# Вопросы по задачам
1) Можно ли делать условный переход по тэгу? if( tag == ..) ... 

2) В Send'е допускается tag == 0. А в методичке сказано, что tag > 0.

# Вопросы из методички Гергеля
1) Все процессы входят в MPI_COMM_WORLD? Даже из разных коммуникаторов?

2) Понятие группа - имеется в виду мн-во процессов, принадлежащих одному коммуникатору?

3) "Логическая топология линий связи между процессами имеет структуру полного графа (независимо от наличия реальных физических каналов связи между процессорами)." 
Но в реальных физ. каналах параметры же другие, чем те, на которые мы ориентировались, используя лог. топологию. Не должно ли это настораживать?

4) int * argc, char **(*) argv? - всё время забываю, шо за фрукт? Сколько звёзд надо? Ближе к какому слову их лучше тыкать? В методичке кол-во звёзд меняется от места к месту, что за магия?

5) Почему include "mpi.h"? Но include <omp.h> ?

6) c.8 - "процессы, между которыми выполняется передача данных, в обязательном порядке должны принадлежать коммуникатору, указываемому в функции MPI_Send;" - а если нет, что будет?

7) с.10 - правильно я понимаю, что как только процесс встречает на своём пути MPI_Recv - он приостанавливает работу и начинает ждать? MPI_Recv = блокирующая для процесса получателя?

8) MPI имеет место в системах с разделённой памятью? ( В отличие от OMP - общей?) ( Отсюда все переменные в MPI как бы типа private - и даже точнее - firstprivate? )

9) А вообще, эти процессы ведь хаотично выполняют параллельный участок? Не по порядку? Нет понятия главной нити исполнения?


3) Я так и не понял твоего вопроса. Просто автор имел в виду, что мы работам с процессами так,
словно каждое ядро связано с каждым. В реальности это может быть не так, они могут связаны через посредников.
И на практике может оказаться так, что время пересылки между разными процессами может быть разное.
Ты не должен зыбывать про это при написании программ.



4) Правильно так:
int main(int argc, char ** argv)
или так
int main(int argc, char * argv[])

Допустим, ты пишешь свою функцию, которую ты будешь вызывать из мейна:
char func(int n);

Здесь ты говоришь, что входящее значение - int n - то, что мейн передаст в функцию при вызове.
Выходящее значение - char - то, что мейн получит от неё.
Но сам по себе мейн - такая же функция, как и func. Отличие в том, что ты не сам её вызываешь, а её
вызывает операционная система, когда ты говоришь ей, чтобы она запустила твою прогу. Тогда ОС открывает
исполняемый файл проги, находит там функцию мейн и вызывает её так же, как и ты вызываешь func из мейна.
И следовательно, мейн так же должен иметь входное и выходные значения.
Выход мейна - int - код работы функции. Говорит ОС о том, успешно ли выполнилась твоя прога.
Вход мейна - два параметра - аргументы командной строки. Это то, с чем вместе ты набирал прогу в шелле.
(Шелл - командная строка линукса).

argc - число аргументов плюс один. Плюс один - это потому, что нулевым аргументом ОС считает название проги.
argv - указатель на двумерный массив символов. В котором каждая строка - новый арумент.
ВНИМАНИЕ! Этот массив - НЕ прямоугольная матрица, то есть, каждая строка имеет РАЗНУЮ длину.

Пример. Ты вызываешь компиляцию проги командой
gcc -o proga.out proga.c
Шелл смотрит на первое слово, понимает, что ты вызываешь gcc, запускает gcc и передаёт ему эти аргументы.
Теперь gcc начинает разбираться, что же шелл ему прислал. Он обнаружит, что:
argc = 4
argv[0] = "gcc\0"
argv[1] = "-o\0"
argv[2] = "proga.out\0"
argv[3] = "proga.c\0"

\0 - Это символ окончания строки.
Рекомендую тебе поразбираться в этом и попробовать передавать в прогу данные именно так, а не scanf'ом.
Пример того, как послать в прогу аргументом количество нитей (для OpenMP) найдёшь у меня в matrix.c



5) Можно и в скобках, и в кавычках. Лучше в скобках.

В чём разница? В том, что если написал в скобках, то препроцессор (привет техпрогу) сначала ищет
указанный *.h файл (он называется хедером или заголовочным файлом) в особой папке среди стандартных хедеров 
(то есть, тех, которые другие люди для тебя написали), а потом - в текущей директории среди твоих
собственных хедеров. А если напишешь в кавычках, то он будет искать в обратном порядке.

Зачем это нужно? Затем, что если ты написал свой хедер, который называется так же, как и стандартный,
то его полюбас нужно брать в кавычки, а то препроцессор подключит не тот.

Но? Но есть хороший стиль программирования: свои хедеры - в кавычки, стандартные - в скобки.



6) Не знаю, что будет, никогда так не делал, но подозреваю, что прога завалится на таком сенде на этапе
выполнения.



7) Да. Подразумевается, что сразу после ресива ты можешь начать использовать полученные данные.
Поэтому разблокировать прогу ДО полного получения данных - ваще не варик.
Вот сенд неблокирующий: ты сказал устройству передачи данных, что хочешь передать и кому, и забыл.



8) Да. Скорее всё же private. Потому что firstprivate предполагает то, что когда-то нити были связаны,
а в момент "развязки" они размножили значение в переменной мастера на все нити.
В MPI же нити никогда не были связаны.

Ну а если точно, то дело было так. Ты, наверное, заметил необычность запуска проги:
mpirun -np 10 a.out
Дело в том что ты запускаешь не саму прогу, а приложение - mpirun, которому говоришь, сколько нитей ты 
хочешь. После чего:
а) mpirun создаёт 10 нитей.
б) Каждая нить в себе запускает a.out.

Всё. Теперь они могут связаться только сообщениями и только внутри MPI-области. А mpirun следит за
работой нитей и говорит тебе, если вдруг что-то пошло не так. Если же все нити спокойно дошли до конца
кода твоей программы и завершились, то mpirun спокойно завершается сам.



9) Ещё раз, параллельного участка нет. Весь код - параллельный участок. Я это объяснил в пункте 8.
Главной нити исполнения нет. Все равноправны. Главный у них - mpirun, но ты им управлять не можешь.



Про теги:

1) Можно. Это условный переход не по тегу, а по переменной, в которой этот тег лежит. Ты её можешь хоть
в консоль напечатать.



2) Не знаю точно, можно ли делать тег равным нулю.
